# (PART) Academic Projects {.unnumbered}

# Wage Determinants

## Introduction

While Salary is one of the most important motivators in labor force, the existence of wage disparity is
inevitable. According to economic theory, it is possible to divide the causes of the disparity wages into two
groups. The first group can include the elements caused by changes in the labor market, the difference or the
change of the working environment at the workplace, due to different differ in the nature of the work or due
to differences in the characteristics of workers themselves. The second group includes causes about social
stigma is either caused by discrimination in society or by people employment for employees. This group of
causes leads to inequality in society. Therefore, in order to (1) determine the level of wage disparity at
Vietnam, (2) identify factors that actually affect wages and (3) decompose the wage gap to clarify the
difference.

To accomplish the above purposes, the writing aims to complete the following goals:
* Introduction to the theoretical basis and applicability of the regression method percentile and wage
differential decomposition method based on percentile regression.
* Regression of percentile function of real wages in Vietnam by means of percentile regression with
bias correction sample selection and endogenous remediation.
* Determine the wage gap by minimum years of experience with the data collected from an online
recruitment platform.

With selected research objectives and research methods, the paper topic has scientific and powerful
meanings:
* The topic applies the percentile regression method, a regression technique was introduced by
Koenker & Bassett (1978) and has been used extensively widespread in the world but not yet
popular in Vietnam. Very few of the Research project in Vietnam applying percentile regression
technique, especially applied in the study of wage function and decomposition wage difference.
* This financial research project presents a concise, complete and systematic way of theory of
percentile regression.
* The wage function of labor groups is estimated using Percentile regression method with adjustment
for selection bias sample and handle endogenous phenomena in the model, giving an estimate solid
and reliable quality.

## Literature Review

In nineteen seventy four, Mincer introduced a wage equation showing the relationship between the logarithm
of income with factors such as years of schooling, work experience, and the square of the experience
variable based on the argument that the amount of wages paid to a person now depends on his or her
previous investment in human capital. However, this equation is quite tough to estimate since it involves a
logarithm and a lot of variables contribute to this complicated model.

**Mincer earnings function:**

$$\ln(\omega)=\ln(\omega_0)+\rho s+ \beta_1x+\beta_2x^2$$
* $\omega$: earnings
* $\omega_0$: earnings of someone with no education and experience
* $s$: years of education
* $x$: years of experience
* $\rho,\beta_1,\beta_2$: regression coefficients

After Card D's research (1994), many other studies extended Mincer's wage equation using different
independent variables in the open Mincer (1974) wage function.
Some typical studies before percentile regression was applied:
* Salary analysis: Starting with the study of Edgewort (1922). Followed by other studies by Becker
(1957),Dunlop (1957), Slichter (1950), Cullen (1956), Dalton & Ford (1977) and Long &
Link(1983), Dickens & Katz (1987), Krueger & Summers(1988) and Groshen (1991), Ferber &
Green (1982); Lindley,Fish and Jackson (1992), Blackaby, Booth and Frank (2005).
* Some typical studies on wage disparity applied in the past: reduce percentiles to the wage function:
Buchinsky (1994) initiated the application of percentile regression method in estimating the function
salary variable regression. Followed by other Fortin studies and Lemieux (1998), Ajwad et al.
(2002), Albrecht et al associates (2003), Machado & Mata (2005), Melly (2006)
Gunawardena(2006) Arulampalam et al (2007), Nestic (2010), Del Río,Gradín&Cantó (2011). 

Very few studies in Vietnam use percentile regression for regression wage function and wage differential
decomposition. Typical can be mentioned to the study of Hung et al (2007a) and Hung T.P and other
associates (2007b).

## Data

The data is collected on recruitment website “careerbuilder.vn” by filtering jobs in Ho Chi Minh city over the finance majoring of Banking, Insurance, Real Estate and Security.

<center>
<img src="https://raw.githubusercontent.com/ThanhDatIU/image/main/wage1.png" width="80%" height="80%">
</center>

Specifically, for a specific recruitment, we shall have the corresponding information including salary,
experience, education, and so on. Frequently, the salary is often hidden or found in a ranging format and the interest of this paper cares only for the minimum years of experience ranging from 8 million and 50 million.

<center>
<img src="https://raw.githubusercontent.com/ThanhDatIU/image/main/wage1.png" width="80%" height="80%">
</center>

Looking at the data frame, it is clear to see that there are 3 categorical variables education, areas and levels.
It is also obvious that age, experience, and salary could be considered as continuous variables.
```{r}
mydata <- read.csv("https://raw.githubusercontent.com/ThanhDatIU/RMF_IU/main/careerbuilder.csv")
```
``` {r, message=FALSE, warning = FALSE,echo=FALSE}
table=mydata
paged_table(table)
``` 

We then turn categorical columns into dummy variables which are numeric variables that represents
categorical data. As a practical matter, regression results are easiest to interpret when dummy variables are
limited to two specific values, 0 or 1. Typically, 1 represents the presence of a qualitative attribute, and 0
represents the absence.

In total, we have 11 binary variables and 3 continuous variables since we only investigate the relationship
between the minimum values of all the continuous variables including minimum age, minimum experience,
and minimum salary.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
df = mydata %>% mutate(
  education=ifelse(university==1,"university",
            ifelse(college==1,"college",
            ifelse(intermediate==1,"intermediate", "education_not_required"))),
  areas=ifelse(banking==1,"banking",
        ifelse(insurance==1,"insurance",
        ifelse(security==1,"security", "real_estate"))),
  levels=ifelse(employee==1,"employee",
         ifelse(observer==1,"observer", ifelse(manager==1,"manager", "chief_manager"))),
  gender=ifelse(male==1,1,ifelse(female==1,1,0)))

df_nogender_agelimited=df %>% 
  filter(age != "not_limited",levels!="chief_manager",gender==0) %>% 
  mutate(min_age=as.numeric(min_age))
```
``` {r, message=FALSE, warning = FALSE,echo=FALSE}
table=df_nogender_agelimited %>% select(education,areas,levels,min_age,max_age,min_exp,max_exp,min_salary,max_salary)
paged_table(table)
``` 

## Methodology

### Linear Regression

* Model equation:
$$y=\beta X$$
* Mean squared error for linear regression
$$MSE=\frac{1}{n} \sum_{i=1}^{n}(y_i-\beta x_i)^2$$
* Minimization problem:
$$\hat\beta = \text{argmin}_\beta \frac{1}{n} \sum_{i=1}^{n} (y_i-\beta x_i)^2$$

The best linear regression model $Y$ equals beta $X$ is estimated by establishing mean squared error measuring the average of the squares of the errors.
Then the coefficients of the OLS are found by coming up with the beta hat such that the mean squared error is minimized.

Similarly, the quantile regression for model is estimated by establishing mean squared error measuring the average of the absolute deviations from a central point.
Then the coefficients of the quantile regression are found by generating the betas hat such that the mean absolute deviation is minimized.

### Quantile Regression

The percentile regression method was introduced by Koenker& Bassett for the first time in 1978.

* Model equation:
$$y=\beta X$$
* Mean squared error for linear regression

$$MAD= \sum_{i:y_i > \beta x_i}^{n}\tau |y_i-\beta x_i| + \sum_{i:y_i < \beta x_i}^{n}(1-\tau) |y_i-\beta x_i|$$

* Minimization problem:

$$\hat\beta = \text{argmin}_\beta \frac{1}{n} \left(\sum_{i:y_i > \beta x_i}^{n}\tau |y_i-\beta x_i| + \sum_{i:y_i < \beta x_i}^{n}(1-\tau) |y_i-\beta x_i| \right)$$
When $\tau$ is one half, the MAD is symmetrical so that the median always has the same number of data points above it as below it.
But if instead the absolute residuals are weighted differently depending on whether they are positive or negative, we can calculate the quantiles of the distribution.
To estimate the tau quantile, we would set the weight on positive observations to tau and that on negative observations to $1 – \tau$.
We can select the quantiles of interest and common choices would be $0.1, 0.5, and 0.9$.

## Results

### Visualization

#### Salary ~ Age

The following snippet demonstrates how we can import the optimal tidyverse package and include the ggplot function to examine the relationship between 2 continuous variables salary and age contained in the x and y of the aesthetic argument.
And what is extremely powerful for this ggplot function is the argument color, shape, and facet wrap allowing us to explain the graph with the other 3 categorical variables areas of finance, levels, and education.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
ggplot(df_nogender_agelimited,
       aes(x=as.numeric(min_age),
           y=min_salary,
           color=areas,
           shape=levels)) + 
  geom_point() + 
  facet_wrap(~education) + 
  labs(x="Minimum Age",
       y="Minimum Salary",
       title = "CareerBuilder Ho Chi Minh City Jobs in 2021") +
  scale_x_continuous(limits=c(18,36))
```

Executing the codes, it’s obvious to suggest that while not so many companies recruit applicant who does not have a degree or studies in an intermediate school, the number of jobs requiring university and college are quite high.
A closer look into the university facet suggests that the correlation coefficients of minimum age and the minimum salary is considerably low implying that linear regression may not be working for this relationship.

#### Salary ~ Exp

On the other hand, when it comes to minimum years of experience as the x-axis, it is obvious to say that there is a strong linear relationship between minimum years of experience and minimum salary.
However, the constant variance assumption may be violated given the fact that data points for 3 minimum years of experience vary much more noticeably than for those who only have one year or less working experience.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
ggplot(df_nogender_agelimited,aes(x=min_exp,y=min_salary,color=areas,shape=levels)) + 
  geom_point() + 
  facet_wrap(~education) +
  labs(title="CareerBuilder Ho Chi Minh City Jobs in 2021",
        x ="Minimum Age", y = "Minimum Salary")+ theme_bw() +
scale_x_continuous(limits=c(0,10),n.breaks=10)
```

### Linear Regression

#### Multiple Linear Regression Model

Using the linear model function in the familiar stats library, it’s clear to see that all the education variables are not significant. 
Insurance is meaningful implying all the areas in finance maybe explain the model. 
The matrix singularity when it comes to the variable level and we may have to drop one factor for later analysis.
But the most important thing that we should take notice of for this linear model is the two continuous variables age and experience. As previously acknowledged, while age is not statistically significant, the minimum experience variable explains the model with the corresponding two-point six.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
male=df_nogender_agelimited$male
female=df_nogender_agelimited$female
university=df_nogender_agelimited$university
college=df_nogender_agelimited$college
intermediate=df_nogender_agelimited$intermediate
education_not_required=df_nogender_agelimited$education_not_required
banking=df_nogender_agelimited$banking
insurance=df_nogender_agelimited$insurance
security=df_nogender_agelimited$security
real_estate=df_nogender_agelimited$real_estate
employee=df_nogender_agelimited$employee
observer=df_nogender_agelimited$observer
manager=df_nogender_agelimited$manager
chief_manager=df_nogender_agelimited$chief_manager
age=df_nogender_agelimited$age
min_age=df_nogender_agelimited$min_age
max_age=df_nogender_agelimited$max_age
min_exp=df_nogender_agelimited$min_exp
max_exp=df_nogender_agelimited$max_exp
min_salary=df_nogender_agelimited$min_salary
max_salary=df_nogender_agelimited$max_salary
education=df_nogender_agelimited$education
areas=df_nogender_agelimited$areas
levels=df_nogender_agelimited$levels
gender=df_nogender_agelimited$gender

## OLS regression
olsreg <- lm(min_salary~university+
                        college+
                        intermediate+
                        education_not_required+
                        banking+
                        insurance+
                        security+
                        real_estate+
                        employee+
                        observer+
                        manager+
                        min_age+
                        min_exp, 
             data=df_nogender_agelimited)
summary(olsreg)
```

>1. Education is not significant. 

>2. Insurance salary  is significant*.

>3. Levels are significant*.

>4. Minimum age is not significant.

>5. Minimum experience is significant*.

#### Simple Linear Regression

##### Areas

So let’s try to use the linear model for only the areas in the finance variable. 
It’s interesting that we can generally summarize the average salary of each of the majors in finance with insurance standing at the highest average salary of 26 million VND. Other majors seem to be consistent in the range from 15 to 18 million per month.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
## OLS regression
olsreg <- lm(min_salary ~ areas+0, data=df_nogender_agelimited)
summary(olsreg)
```

>6. Banking salary is 15 million VND on average.

>7. Insurance salary is 26 million VND on average.

>8. Real estate salary is 18 million VND on average.

>9. Security salary is 16 million VND on average.

```{r}
ggplot(df_nogender_agelimited,aes(x=as.factor(areas),y=min_salary,color=education)) + 
  geom_point() +
  theme_bw()
```

#### Levels

Chances are a manager will earn the minimum salary more than 26 million which is considerably higher than the number of all of the observers and employees 14 and 18 million respectively.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
## OLS regression
olsreg <- lm(min_salary ~ levels+0, data=df_nogender_agelimited)
summary(olsreg)
```

>10. Manager salary is 26 million VND on average.

>11. Observer salary is 18 million VND on average.

>12. Employee salary is 14 million VND on average.

```{r}
ggplot(df_nogender_agelimited,
       aes(x=factor(levels,levels=c("employee","observer","manager")),
           y=min_salary,color=education)) + 
  geom_point() +
  theme_bw()
```

#### Experience

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
## OLS regression
olsreg <- lm(min_salary ~ min_exp, 
             data=df_nogender_agelimited)
summary(olsreg)
```

>13. Experience is significant, for 1 more year of experience the average salary should increase by 3 million VND.

```{r}
ggplot(df_nogender_agelimited,
       aes(x=as.numeric(min_exp),
           y=min_salary,
           color=education)) + 
  geom_point()
```

And lastly, for the continuous variable experience despite the highly significant estimate, the model for this is working so well with the multiple R squared of only 30 percent. And that’s why we need Quantile Regression.

### Quantile Regression

#### Table

>1. Drop observer for avoiding matrix singularity. 

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
quantreg.all <- rq(min_salary~banking+
                     insurance+
                     security+
                     real_estate+
                     employee+
                     manager+
                     min_exp, tau = seq(0.05, 0.95, by = 0.05),                   
                   data=df_nogender_agelimited)
quantreg.plot <- summary(quantreg.all)
plot(quantreg.plot,xlim=c(0,1),ylim=c(-6,11))
```

>2. Insurance could be predicted using OLS.

>3. Employee could be predicted using OLS.

>4. Manager could be predicted using OLS.

>5. And so Observer could be predicted using OLS.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
quantreg.all <- rq(min_salary~min_exp, 
                   tau = seq(0.05, 0.95, by = 0.05), 
                   data=mydata)
quantreg.plot <- summary(quantreg.all)
plot(quantreg.plot,xlim=c(0,1),ylim=c(2,4.5))
```

>6. Minimum experience cannot be predicted using OLS for salary less than 55% and greaterr than 80% or less than 31$ million VND or greater than 41.5$ million VND*. 

Regressing Salary with only Minimum Years of Experience variable, the distinct disparity across the ranges seems to be more observable. The next step would be employing some visualizing tools to illustrate how the coefficients vary across the percentiles.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
library(broom)
quantreg.all <- rq(min_salary~min_exp, 
                   tau = seq(0.05, 0.95, by = 0.05), 
                   data=mydata)

quantreg.tidied <- tidy(quantreg.all)

library(tidyr)
quantreg.wide=quantreg.tidied %>% 
  select(term,tau,estimate) %>% 
  spread(tau,estimate)
```
``` {r, message=FALSE, warning = FALSE,echo=FALSE}
paged_table(quantreg.wide)
``` 

#### Graph

##### Salary ~ min_age

In terms of min_age, the coefficients are significant with the lower 45 percentile, the coefficients are significantly different from the confidence internals of the OLS with the minimum reaching 1 at 5 percent lower tail. The opposite is true for the upper 80 percentile where the maximum coefficient stood at exactly 5 when we are considering the 5 percent upper tail.

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
ggplot(df_nogender_agelimited,aes(x=as.numeric(min_age),y=min_salary)) + 
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_quantile(quantiles=c(1:9/10),color="red") +
  scale_x_continuous(limits=c(18,36))
```

##### Salary ~ min_exp

``` {r, message=FALSE, warning = FALSE,echo=FALSE}
##### Salary ~ Exp
ggplot(df_nogender_agelimited,aes(x=min_exp,y=min_salary)) + 
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_quantile(quantiles=c(1:9/10),color="red") +
  scale_x_continuous(limits=c(0,10),n.breaks=10)
```

The above scatter plot compares the performance of Linear Model and Quantile Model. It is obvious to suggest that Quantile represents a more natural and flexible way to capture the complexities inherent in the relationship by estimating models for the conditional quantile functions.

## Conclusions

The percentile regression approach, which was first developed by Koenker and Bassett (1978) and is widely used throughout the world but not yet popular in Vietnam, is employed in this project. Only a few research projects in Vietnam use the percentile regression approach, which is particularly useful for studying pay functions and decomposing wage differences. The financial report explains percentile regression theory in a clear, comprehensive, and systematic manner. The pay function of labor groups is estimated using the percentile regression approach with selection bias sample correction and endogenous phenomena handled in the model, yielding a solid and trustworthy estimate.

The experience gap across pay distribution was examined in depth in the previous sections using data from Careerbuilder.vn There is a quantile impact for salaries less than 27 million and more than 40 million, according to the aggregate results of the entire sample. The reason for this might be that a finance major may need more than two years of work experience in order for an employee to earn a reasonable wage.
 
Other than those accomplishments, the code snippet acknowledged in the Appendix could be considered as a typical source for learning Regression model in RStudio.

## References

Koenker, R. and Bassette, G., 1978. Regression quantiles. [online] Available at: <https://www.jstor.org/stable/1913643>
Tran, T. A. T. (2018, February). Investigating the gender wage gap in Vietnam by quantile regression: Sticky floor or glass ceiling. [online] Available at: https://www.researchgate.net/publication/323870909_Investigating_the_gender_wage_gap_in_Vietnam_by_ quantile_regression_Sticky_floor_or_glass_ceiling
Tran, T. A. T. (2014, June). Ước lượng hàm hồi quy tiền lương ở Việt Nam giai đoạn 2002 - 2010 bằng thủ tục Heckman hai bước. [online] Available at: http://jabes.ueh.edu.vn/Home/SearchArticle?article_Id=2e855945-ac00-487d-a4f7-8bcec142927f

# Life Expenctancy

## Mortality rates

The following codes compare mortality rates across the ages ranging from zero to one hundred and ten. 
```{r}
full_df = read.csv("/cloud/project/csvfiles/full_df.csv") %>% mutate(qx = as.numeric(qx),
              lx = as.numeric(lx),
              dx = as.numeric(dx),
              year= as.numeric(year),
              Age = age)

# Filter USA, 2019. line: qx~Age by gender
ggplot(full_df %>% 
         filter(country=="USA",
                year==2019), 
       aes(x=Age, y=qx,group=1)) +
geom_line(col="blue") +
labs(x="Age x", 
     y= expression(paste("Mortality rate ", 
                         q[x])),
     title="Mortality rates (U.S.A., 2019)") +
facet_wrap(~gender)
```
The look is similar to the graph of an exponential function so it is suggested that taking logarithm and we may have further insights.
```{r}
# Filter USA, 2019. line: log(qx)~Age by gender
ggplot(full_df %>% 
         filter(country=="USA",
                year==2019), 
       aes(x=Age, y=log(qx),group=1)) +
geom_line(col="blue") +
labs(x="Age x", 
     y= expression(paste("Log Mortality rate ", 
                         q[x])),
     title="Log Mortality rates (U.S.A., 2019)") +
facet_wrap(~gender)
```
A glance at this log mortality graph indicates three important features of the evolution of mortality rates:

1. The rate for infants is locally high for the newborns, then it decreases.  
2. It shows an upward hiccup around the age of eighteen. This is called the accident hump. The accident hump is often caused by increased fatalities from car accidents and is (usually more pronounced) in males compared to females.  
3. And then it straightens back again, reflecting the human aging process.  

## Survival probablity

It is convenient to illustrate this section using examples. We calculate the 5-year survival probability of an 18-year-old. First extract px as 1 minus qx stored in the life table. We need the survival probability of an 18-year old until a 22-year-old. We then multiply these one-year survival probabilities to get the 5-year survival probability. Using the prod() function on the vector of relevant one-year survival probabilities gives you the result.
$${}_{k}p_{x}=p_x.p_{x+1}...p_{x+k-1}$$
Alternatively, we could evaluate this probability as the division of the number of alive people $l_x$ in different ages. Up to rounding errors, both calculations lead to the same result!
$${}_{k}p_{x}=\frac{l_{x+k}}{l_{x}}$$
```{r}
# Filter USA,2019, Age>=18
# Add column survival
# line: survival~1:92 (18-110) by gender
ggplot(full_df %>% 
         filter(country=="USA",
                year==2019,
                Age>=18) %>% 
         group_by(gender) %>% 
         mutate(survival=cumprod(1-qx),
                k=0:(n()-1)) %>% 
         ungroup(),
       aes(x=k,y=survival)) +
geom_line(col="blue") +
labs(x="k", 
     y=expression(paste(""[k], "p"[18])),
     title="Survival probabilities for people 
            in age 18, 2019, U.S.A.") +
facet_wrap(~gender)
```
This graph indicates the probability of how many more years people would still be alive after the age of eighteen, for example, the chance of an eighteen girl to survive more fifty years up to sixty-eight years old should be about ninety percent.

## Life expectancy

Let's start from the future lifetime, $K_x$, that is the number of whole years lived by (x). The probability that Kx takes value k is the probability that an x-year-old survives k years and then dies within the next year, at age x+k. Further manipulation shows that this probability is the difference between the k and the (k+1)-year survival probability of an x-year-old. 
$$P(K_x=k)={}_{k}p_{x}.q_{x+k}={}_{k}p_{x}-{}_{k+1}p_{x}$$
We can verify this equivalence empirically for the example of an 18-year-old. What is his 5-year deferred mortality probability? In the first expression you apply the reasoning with the 5-year survival probability and the mortality rate at age 23, while the second expression takes the difference between the 5- and the 6-year survival probability. Both expressions lead to the same result!

$${}_{k}p_{x}.q_{x+k}$$

$${}_{k}p_{x}-{}_{k+1}p_{x}$$

Using the probability function of $K_x$, it is now straightforward to calculate the expected value of this random variable. That is the life expectancy of an x-year-old, expressed in whole years. For each possible outcome k, you multiply k with the probability that $K_x$ realizes this outcome. Taking the sum then results in the life expectancy. Further simplification leads to a simple expression: the sum of the k-year survival probabilities when k runs from 1 to its maximum possible value.

$$E[K_x]= \sum_{k=0}^{\infty} k \times P(K_x=k) = \sum_{k=0}^{\infty} k \times ({}_{k}p_{x}-{}_{k+1}p_{x}) =  \sum_{k=1}^{\infty}{}_{k}p_{x}$$
```{r}
# Function to compute the curtate expected future lifetime for a given age and life table
curtate_future_lifetime <- function(age, life_table) {
  px <- 1-life_table$qx
  kpx <- cumprod(px[(age+1):length(px)])
  sum(kpx)
}

# Vector of ages
ages <- (full_df %>% 
           filter(country=="USA",
                  year==2019,
                  gender=="F") %>% 
           mutate(Age=replace_na(Age,110)))$Age

# Curtate future lifetimes for all ages
future_lifetimes <- sapply(ages, 
                           curtate_future_lifetime, 
                           full_df %>% 
                             filter(country=="USA",
                                    year==2019,
                                    gender=="F") %>% mutate(Age=replace_na(Age,110)))



# Future lifetime by age
plot(ages, 
     future_lifetimes,
     type = 'l', 
     lwd = 2, 
     col = "green", 
     xlab = "Age x", 
     ylab = "Future lifetime", 
     main = "Future lifetime by age, females, 2019, U.S.A.")
```
So it’s quite intuitive that women in the USA live up to 80 years old, and for each more age they live the expected value decreases by 1 forming the linear pattern from zero to eighty, after which we see the extreme cases following just a small little tail.
```{r}
# Filter USA. line qx~Age by gender, color by year
ggplot(full_df %>% 
         filter(country == "USA"), 
       aes(x=Age, y=qx, color = year)) +
geom_line(aes(group = year)) + 
facet_wrap(~gender) +
labs(x="Age x", 
     y= expression(paste("Mortality rate ", q[x])),
     title="Mortality rates (USA, 1933-2019)")
```
Adding another dimension year to the plot with the attribute color, it is obvious to say as the years proceeded, the mortality rate has been stably improved and thus firmly decreased.
We could try to compare the lifetime across the year between males and females:
```{r}
# Filter USA. 
# Add column life_expectancy
# line: life_expectancy~year, color by gender
ggplot(full_df %>% 
         filter(country == "USA") %>% 
         group_by(gender,year) %>% 
         mutate(kpx=cumprod(1-qx),
                life_expectancy=sum(kpx)) %>% 
         filter(Age==0) , 
       aes(x=year, y = life_expectancy, color = gender)) +
geom_line() + 
labs(x="Year", 
     y= "Life Expectancy",
     title="Life Expectancy, U.S.A.")
```
It is evident to suggest that women outlived, outlive and will outlive men.

## 40 Countries Data

```{r}
# Add column life_expectancy. 
# Filter Age=0, interesting countries
# scatter:life_expectancy~year color by country by gender
ggplot(full_df %>%
         group_by(year,country,gender) %>% 
         mutate(Age=replace_na(Age,110),
                kpx=cumprod(1-qx),
                life_expectancy=sum(kpx)) %>% 
                filter(Age==0) %>% 
                ungroup(),
       aes(x=year,y=life_expectancy,color=country)) + 
geom_point() +
facet_wrap(~gender) +
ggtitle("Lifetime through years in 40 countries between men and women") +
  xlab("Year") + ylab("Life Expectancy")
```

This colorful scatter plot summarizes how the data of 800.000 entries behave when it comes to life duration among top-ranking countries across the years. This may be overwhelming but this gives the strongest evidence for developing lifetime as years going by. What’s more, while the maximum (point of) males is just higher than eighty, that of females converges to the age of ninety just for the next few years.